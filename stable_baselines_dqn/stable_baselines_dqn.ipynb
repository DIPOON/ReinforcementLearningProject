{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyyN-2qyK_T2"
   },
   "source": [
    "# Minesweeper solver with Stable Baselines3 DQN\n",
    "\n",
    "References\n",
    "> 1. [(medium) article for stable baselines](https://towardsdatascience.com/stable-baselines-a-fork-of-openai-baselines-reinforcement-learning-made-easy-df87c4b2fc82)\n",
    "> 1. [(colab) example of medium article](https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/master/saving_loading_dqn.ipynb)\n",
    "> 1. [(github) minesweeper gym environment](https://github.com/aylint/gym-minesweeper)\n",
    "\n",
    "Helps\n",
    "> 1. [(github) stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
    "> 1. [(github) stable-baselines3-contrib](https://github.com/Stable-Baselines-Team/stable-baselines3-contrib)\n",
    "> 1. [(github) stable-baselines](https://github.com/hill-a/stable-baselines)\n",
    "> 1. [(doc) stable-baselines](https://stable-baselines.readthedocs.io/en/master/)\n",
    "> 1. [(doc) stable-baselines3](https://stable-baselines3.readthedocs.io/en/master/index.html)\n",
    "> 1. [(doc) stable-baselines3-contrib](https://sb3-contrib.readthedocs.io/en/master/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32163,
     "status": "ok",
     "timestamp": 1653442503910,
     "user": {
      "displayName": "Gyeongheon Lee",
      "userId": "09300670283340891360"
     },
     "user_tz": -540
    },
    "id": "bC6ssh-iDeWj",
    "outputId": "7dad0010-0612-4180-e6b1-2bd8e440b104"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1653443597762,
     "user": {
      "displayName": "Gyeongheon Lee",
      "userId": "09300670283340891360"
     },
     "user_tz": -540
    },
    "id": "YZQ9HP09CLCu"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import TensorBoardOutputFormat, configure\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "#from stable_baselines3.her.her_replay_buffer import HerReplayBuffer\n",
    "from typing import Callable\n",
    "\n",
    "from minesweeper_gym_env import MinesweeperEnv\n",
    "from MinesweeperModifiedEnv import MinesweeperModifiedEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1653444581265,
     "user": {
      "displayName": "Gyeongheon Lee",
      "userId": "09300670283340891360"
     },
     "user_tz": -540
    },
    "id": "QzSFVG-1cnFu"
   },
   "outputs": [],
   "source": [
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    :param observation_space: (gym.Space)\n",
    "    :param features_dim: (int) Number of features extracted.\n",
    "        This corresponds to the number of unit for the last layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 512):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.sample()[None].shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 128, kernel_size=3, stride=1, padding='same', bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding='same', bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding='same', bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding='same', bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[None]).float()\n",
    "            ).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten, features_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_dim, features_dim, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=512),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1653443603558,
     "user": {
      "displayName": "Gyeongheon Lee",
      "userId": "09300670283340891360"
     },
     "user_tz": -540
    },
    "id": "zKDTOVah6h64"
   },
   "outputs": [],
   "source": [
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    #lr0 = initial_value\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining: = 1.0 - (num_timesteps / total_timesteps)\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        if progress_remaining > 0.8:\n",
    "            return initial_value\n",
    "        else:\n",
    "            return progress_remaining * initial_value * 1.25\n",
    "        #return progress_remaining * initial_value\n",
    "        #nonlocal lr0\n",
    "        #lr0 = max(0.001, lr0 * 0.99975) # 0.99975\n",
    "        #return lr0\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2p29feu2O9WH"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, env, num_episodes=10000):\n",
    "    \"\"\"\n",
    "    Evaluate a RL agent\n",
    "    :param model: (BaseRLModel object) the RL Agent\n",
    "    :param num_steps: (int) number of timesteps to evaluate it\n",
    "    :return: (float) Mean reward for the last 100 episodes\n",
    "    \"\"\"\n",
    "    episode_rewards = [0.0]\n",
    "    episode_wins = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_rewards.append(0.0)\n",
    "        #if i % 100 == 1:\n",
    "        #    print('Playing episode {}'.format(i))\n",
    "        while True:\n",
    "            action, _states = model.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            episode_rewards[-1] += reward\n",
    "            if done:\n",
    "                episode_wins.append(info.get('is_success'))\n",
    "                break\n",
    "            elif info.get('num_actions') > 200:\n",
    "                #print('Episode {}. Over action in obs, action: \\n{}, {}'.format(i, obs, action))\n",
    "                episode_wins.append(False)\n",
    "                break\n",
    "    \"\"\"\n",
    "    # Compute mean reward for the last 100 episodes\n",
    "    mean_100ep_reward = round(np.mean(episode_rewards[-100:]), 1)\n",
    "    print(\"Mean reward:\", mean_100ep_reward, \"Num episodes:\", len(episode_rewards))\n",
    "    \"\"\"\n",
    "    win_rate = round(np.mean(episode_wins), 2)\n",
    "    print(\"Win rates:\", win_rate, \"Num episodes:\", len(episode_wins))\n",
    "    \n",
    "    return episode_rewards, episode_wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWN44VDPN25I"
   },
   "source": [
    "## DQN for Oirginal Minesweeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1653444849304,
     "user": {
      "displayName": "Gyeongheon Lee",
      "userId": "09300670283340891360"
     },
     "user_tz": -540
    },
    "id": "zAUvfIZBCDdL"
   },
   "outputs": [],
   "source": [
    "env = MinesweeperModifiedEnv(4, 1)\n",
    "model = DQN('CnnPolicy', env, \n",
    "            learning_rate=linear_schedule(0.001), \n",
    "            policy_kwargs=policy_kwargs,\n",
    "            batch_size=64, \n",
    "            gamma=0.1, \n",
    "            train_freq=(1, 'episode'), \n",
    "            learning_starts=1,\n",
    "            exploration_fraction=0.16, \n",
    "            exploration_initial_eps=0.95, \n",
    "            exploration_final_eps=0.01,\n",
    "            tensorboard_log=\"./dqn_tensorboard/\", verbose=0\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ASA9d8QrDtQ0"
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=int(1e5), \n",
    "            log_interval=10,\n",
    "            tb_log_name='s4m1',\n",
    "            reset_num_timesteps=True)\n",
    "model.save(\"dqn_minesweeper_test_env\")\n",
    "del model  # delete trained model to demonstrate loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rates: 0.88 Num episodes: 1000\n",
      "mean_reward: 1.34\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"dqn_minesweeper_s4m1\")\n",
    "episode_rewards, episode_wins = evaluate(model, env=env, num_episodes=1000)\n",
    "mean_reward = round(np.mean(episode_rewards), 2)\n",
    "print('mean_reward: {}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3131429/1072893841.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  shape=(1, self.board_size, self.board_size), dtype=np.int)\n",
      "/tmp/ipykernel_3131429/1072893841.py:97: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.valid_actions = np.ones((self.board_size * self.board_size), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rates: 0.57 Num episodes: 1000\n",
      "mean_reward: -4.82\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"dqn_minesweeper_s4m2\")\n",
    "episode_rewards, episode_wins = evaluate(model,\n",
    "                                         env=MinesweeperDiscreetEnv(),\n",
    "                                         num_episodes=1000)\n",
    "mean_reward = round(np.mean(episode_rewards), 2)\n",
    "print('mean_reward: {}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3131429/1493132668.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  shape=(1, self.board_size, self.board_size), dtype=np.int)\n",
      "/tmp/ipykernel_3131429/1493132668.py:97: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.valid_actions = np.ones((self.board_size * self.board_size), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rates: 0.54 Num episodes: 1000\n",
      "mean_reward: -0.04\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"dqn_minesweeper_s5m3\")\n",
    "episode_rewards, episode_wins = evaluate(model,\n",
    "                                         env=MinesweeperDiscreetEnv(),\n",
    "                                         num_episodes=1000)\n",
    "mean_reward = round(np.mean(episode_rewards), 2)\n",
    "print('mean_reward: {}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3131429/1493132668.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  shape=(1, self.board_size, self.board_size), dtype=np.int)\n",
      "/tmp/ipykernel_3131429/1493132668.py:97: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self.valid_actions = np.ones((self.board_size * self.board_size), dtype=np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rates: 0.27 Num episodes: 1000\n",
      "mean_reward: -10.81\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"dqn_minesweeper_s5m3_wr0.29\")\n",
    "episode_rewards, episode_wins = evaluate(model,\n",
    "                                         env=MinesweeperDiscreetEnv(),\n",
    "                                         num_episodes=1000)\n",
    "mean_reward = round(np.mean(episode_rewards), 2)\n",
    "print('mean_reward: {}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN for Modified Minesweeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MinesweeperModifiedEnv(4, 1)\n",
    "model = DQN('CnnPolicy', env, \n",
    "            learning_rate=linear_schedule(0.001), \n",
    "            policy_kwargs=policy_kwargs,\n",
    "            batch_size=64, \n",
    "            gamma=0.1, \n",
    "            train_freq=(1, 'episode'), \n",
    "            learning_starts=1,\n",
    "            exploration_fraction=0.16, \n",
    "            exploration_initial_eps=0.95, \n",
    "            exploration_final_eps=0.02,\n",
    "            tensorboard_log=\"./custom_dqn_tensorboard/\", verbose=0\n",
    "           )\n",
    "model.learn(total_timesteps=int(5e5), \n",
    "            log_interval=10,\n",
    "            tb_log_name='s4m1',\n",
    "            #eval_log_path='eval_test',\n",
    "            reset_num_timesteps=True)\n",
    "model.save(\"custom_dqn_minesweeper_s4m1\")\n",
    "del model  # delete trained model to demonstrate loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(\"custom_dqn_minesweeper_s4m1w8\")\n",
    "episode_rewards, episode_wins = evaluate(model, env=MinesweeperModifiedEnv(4, 1), num_episodes=1000)\n",
    "mean_reward = round(np.mean(episode_rewards), 2)\n",
    "print('mean_reward: {}'.format(mean_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "d2atE5vL8L2g",
    "BEazdwPFKZun",
    "9x47HdO6KPQ8",
    "Nsju026AQg0z",
    "AeDD26lyVwJP"
   ],
   "name": "sketchbook.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/Stable-Baselines-Team/rl-colab-notebooks/blob/master/saving_loading_dqn.ipynb",
     "timestamp": 1652336425341
    }
   ]
  },
  "kernelspec": {
   "display_name": "sketchbook",
   "language": "python",
   "name": "sketchbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
